# NGINX Ingress Controller (Common Values)
nameOverride: "nginx-ingress-controller"

controller:
  podLabels:
    app: nginx-ingress-controller

  # Define requests resources to avoid probe issues due to CPU utilization in busy nodes
  # ref: https://github.com/kubernetes/ingress-nginx/issues/4735#issuecomment-551204903
  # Ideally, there should be no limits.
  # https://engineering.indeedblog.com/blog/2019/12/cpu-throttling-regression-fix/
  resources:
    #  limits:
    #    cpu: 1
    #    memory: 1Gi
    requests:
      cpu: 500m
      memory: 512Mi

  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

  replicaCount: 3
  minAvailable: 3

  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 12
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: 60

  tolerations: # This rule ensures that during scheduling time the application must be placed on nodes dedicated=edge
    - key: "dedicated"
      operator: "Equal"
      value: "utility"
      effect: "NoSchedule"
#    - key: dedicated
#      operator: Equal
#      value: edge
#      effect: NoSchedule

  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        # This rule ensures that during scheduling time the application pods will be spread across AZ's
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app: nginx-ingress-controller
            topologyKey: failure-domain.beta.kubernetes.io/zone
          weight: 40
        # This rule ensures that during scheduling time the application pods will be spread across different region(s)
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app: nginx-ingress-controller
            topologyKey: failure-domain.beta.kubernetes.io/region
          weight: 60
        # This rule ensures that during scheduling time the application pods will not share the same node
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app: nginx-ingress-controller
            topologyKey: kubernetes.io/hostname
          weight: 80

#    nodeAffinity: # This rule ensures that during scheduling time the application must be placed on nodes dedicated=edge
#      requiredDuringSchedulingIgnoredDuringExecution:
#        nodeSelectorTerms:
#          - matchExpressions:
#              - key: dedicated
#                operator: In
#                values:
#                  - edge

%{ if aws_nlb_with_tls_termination_at_lb }
# Creating an NGINX Ingress Controller with Network Load Balancer ("nlb-ip") with TLS Termination at Load Balancer level
  config:
    use-proxy-protocol: "true"
    http-snippet: |
      server {
        listen 8080 proxy_protocol;
        return 308 https://$host$request_uri;
      }
  service:
    targetPorts:
      http: 8080
      https: http
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: "*"
      service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp
      service.beta.kubernetes.io/aws-load-balancer-ssl-ports: "443"
      service.beta.kubernetes.io/aws-load-balancer-ssl-cert: ${aws_certificate_arn}
      service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy: ELBSecurityPolicy-TLS-1-2-2017-01
      service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: 'true'
      service.beta.kubernetes.io/aws-load-balancer-type: "nlb-ip"
%{ else }
  hostNetwork: true
  publishService:
      enabled: true
  service:
      annotations:
          service.beta.kubernetes.io/aws-load-balancer-type: nlb
%{ endif }